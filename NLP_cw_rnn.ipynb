{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_cw.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJh4PV2irJIK",
        "colab_type": "code",
        "outputId": "393ece03-4e58-4221-e4b2-29ecc519b033",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 23.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 30.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 35.2MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 36.6MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 22.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 20.0MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 18.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 18.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 18.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 18.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 18.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 18.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 18.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.11.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.5)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.14.15)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDcxSLX74LD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats.stats import pearsonr\n",
        "from os.path import exists\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM\n",
        "import numpy as np\n",
        "from sklearn import linear_model\n",
        "from sklearn.svm import SVR\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim.adam\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ2Jb-Ikq523",
        "colab_type": "code",
        "outputId": "c5cb9beb-6403-42ca-db9a-af6ed2d07785",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "source": [
        "if not exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-20 08:58:06--  https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
            "Resolving competitions.codalab.org (competitions.codalab.org)... 129.175.22.230\n",
            "Connecting to competitions.codalab.org (competitions.codalab.org)|129.175.22.230|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2e1d280e798937e2a8e9c1b865171b93db6642a349962781f0997dd43dffa7ac&X-Amz-Date=20200220T085807Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200220%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
            "--2020-02-20 08:58:07--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=2e1d280e798937e2a8e9c1b865171b93db6642a349962781f0997dd43dffa7ac&X-Amz-Date=20200220T085807Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200220%2Fnewcodalab%2Fs3%2Faws4_request\n",
            "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
            "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 870893 (850K) [application/zip]\n",
            "Saving to: ‘enzh_data.zip’\n",
            "\n",
            "enzh_data.zip       100%[===================>] 850.48K  1.02MB/s    in 0.8s    \n",
            "\n",
            "2020-02-20 08:58:09 (1.02 MB/s) - ‘enzh_data.zip’ saved [870893/870893]\n",
            "\n",
            "Archive:  enzh_data.zip\n",
            "  inflating: dev.enzh.mt             \n",
            "  inflating: dev.enzh.scores         \n",
            "  inflating: dev.enzh.src            \n",
            "  inflating: test.enzh.mt            \n",
            "  inflating: test.enzh.src           \n",
            "  inflating: train.enzh.mt           \n",
            "  inflating: train.enzh.src          \n",
            "  inflating: train.enzh.scores       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lE0oDcaGCFOM",
        "colab_type": "code",
        "outputId": "e47bfd24-d1a0-4d5e-9199-54395a39e5ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"---EN-ZH---\")\n",
        "print()\n",
        "\n",
        "with open(\"./train.enzh.src\", \"r\") as enzh_src:\n",
        "  enzh_train_src1 = enzh_src.readlines()\n",
        "with open(\"./train.enzh.mt\", \"r\",encoding=\"utf-8\") as enzh_mt:\n",
        "  enzh_train_mt1 = enzh_mt.readlines()\n",
        "with open(\"./train.enzh.scores\", \"r\") as enzh_scores:\n",
        "  enzh_train_scores1 = enzh_scores.readlines()"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---EN-ZH---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Du132T5GrMGI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5ceb16ba-97d7-4a94-9e4f-d282d286d67f"
      },
      "source": [
        "with open(\"./dev.enzh.src\", \"r\") as enzh_src:\n",
        "  enzh_dev_src1 = enzh_src.readlines()\n",
        "with open(\"./dev.enzh.mt\", \"r\",encoding=\"utf-8\") as enzh_mt:\n",
        "  enzh_dev_mt1 = enzh_mt.readlines()\n",
        "with open(\"./dev.enzh.scores\", \"r\") as enzh_scores:\n",
        "  enzh_dev_scores1 = enzh_scores.readlines()\n",
        "\n",
        "with open(\"./test.enzh.src\", \"r\") as enzh_src:\n",
        "  enzh_dev_src = enzh_src.readlines()\n",
        "with open(\"./test.enzh.mt\", \"r\",encoding=\"utf-8\") as enzh_mt:\n",
        "  enzh_dev_mt = enzh_mt.readlines()\n",
        "\n",
        "enzh_train_src = enzh_train_src1 + enzh_dev_src1\n",
        "enzh_train_mt = enzh_train_mt1 + enzh_dev_mt1\n",
        "enzh_train_scores = enzh_train_scores1 + enzh_dev_scores1\n",
        "\n",
        "print(len(enzh_dev_src))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-NruUkJHD9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "def writeScores(method_name,scores):\n",
        "  fn = \"predictions.txt\"\n",
        "  print(\"\")\n",
        "  with open(fn, 'w') as output_file:\n",
        "    for idx,x in enumerate(scores):\n",
        "      output_file.write(f\"{x}\\n\")\n",
        "def writeToFile(predictions):\n",
        "  writeScores(\"LSTM\",predictions)\n",
        "  with ZipFile(\"en-zh_lstm.zip\",\"w\") as newzip:\n",
        "\t  newzip.write(\"predictions.txt\")\n",
        "  files.download('en-zh_lstm.zip')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLOTamyRx2fJ",
        "colab_type": "code",
        "outputId": "151e347a-925c-4eb4-ffbe-8eb2a31006f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "use_GPU = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_GPU else \"cpu\")\n",
        "if use_GPU:\n",
        "    torch.cuda.manual_seed(0)\n",
        "print(\"Using GPU: {}\".format(use_GPU))"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using GPU: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p2Rij26PioA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  # Example\n",
        "  # marked_text_en = [\n",
        "  #             \"The last conquistador then rides on with his sword drawn.\",\n",
        "  #             \"He shoves Owen into the pit where Digger rips out his son's heart.\",\n",
        "  #             \"Alpha Phi Alpha also participates in the March of Dimes' WalkAmerica and raised over $181,000 in 2006.\",\n",
        "  #             \"In 1995, Deftones released their debut album Adrenaline.\",\n",
        "  #             \"Kyrgios also supports the North Melbourne Kangaroos Football Club in the Australian Football League.\"\n",
        "  # ]\n",
        "  # marked_text_zh = [、\n",
        "  #           \"最后的征服者骑着他的剑继续前进.\",\n",
        "  #           \"他把欧文扔进了挖掘机挖出儿子心脏的坑里.\",\n",
        "  #           \"Alpha Phi Alpha 还参加了 Dimes WalkAmerica 的 3 月活动 ， 并在 2006 年筹集了 181 000 美元。\",\n",
        "  #           \"1995 年 ， Deftones 发行了首张专辑《肾上腺素》。\",\n",
        "  #           \"基尔吉奥斯还在澳大利亚足球联盟中支持北墨尔本袋鼠足球俱乐部.\"\n",
        "  # ]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0ZhWdDhv-tG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenization(marked_text_en, marked_text_zh, tokenizer):\n",
        "\n",
        "  indexed_tokens = []\n",
        "  tokenized_text = []\n",
        "  segments_ids = []\n",
        "\n",
        "  for i in range(len(marked_text_en)):\n",
        "\n",
        "    txt = \"[CLS] \"+ marked_text_en[i] +\" [SEP] \" + marked_text_zh[i] + \" [SEP]\"\n",
        "    tokens = tokenizer.tokenize(txt)\n",
        "\n",
        "    tmp = tokens.index(\"[SEP]\")\n",
        "    sep1 = [0]*(tmp+1)\n",
        "    sep2 = [1]*(len(tokens)-tmp - 1)\n",
        "    segments_ids.append(torch.tensor([sep1+sep2]))\n",
        "\n",
        "    tokenized_text.append(tokens)\n",
        "    indexed_tokens.append(torch.tensor([tokenizer.convert_tokens_to_ids(tokens)]))\n",
        "\n",
        "  return indexed_tokens, segments_ids "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlK8YvzrxXUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bertProcessing(indexed_tokens,segments_ids,model):\n",
        "\n",
        "  sentences_embedding = []\n",
        "  \n",
        "  with torch.no_grad():\n",
        "      \n",
        "      for i in range(len(indexed_tokens)):\n",
        "\n",
        "        # \"encoded_layers\" has shape [12 x 1 x 22 x 768]\n",
        "        encoded_layers, _ = model(indexed_tokens[i].to(device), segments_ids[i].to(device))\n",
        "\n",
        "        # print(\"-\"*30)\n",
        "        # print (\"Number of layers:\", len(encoded_layers))\n",
        "        # layer_i = 0\n",
        "        # print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
        "        # batch_i = 0\n",
        "        # print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
        "        # token_i = 0\n",
        "        # print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))\n",
        "        \n",
        "        token_embeddings = torch.stack(encoded_layers, dim=0)\n",
        "\n",
        "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
        "\n",
        "        token_embeddings = token_embeddings.permute(1,0,2)\n",
        "\n",
        "        # print(token_embeddings.size())    \n",
        "\n",
        "        # \"token_embeddings\" has shape [22 x 12 x 768]\n",
        "        token_vecs_sum = []\n",
        "\n",
        "        for token in token_embeddings:\n",
        "          sum_vec = torch.sum(token[-4:],dim=0)\n",
        "          token_vecs_sum.append(sum_vec)\n",
        "\n",
        "        # \"token_vecs\" is a tensor with shape [22 x 768]\n",
        "        token_vecs = torch.stack(token_vecs_sum,dim=0)\n",
        "\n",
        "        # Calculate the average of all 22 token vectors.        \n",
        "        sentence_embedding = torch.mean(token_vecs, dim=0)\n",
        "\n",
        "        # print(sentence_embedding.size())\n",
        "        sentences_embedding.append(sentence_embedding.cpu().detach().numpy())\n",
        "\n",
        "  return np.array(sentences_embedding)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcdjr0PY3nEj",
        "colab_type": "code",
        "outputId": "6a88984f-c14c-41e1-e541-6809e91361f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = BertModel.from_pretrained('bert-base-multilingual-cased')"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The pre-trained model you are loading is a cased model but you have not set `do_lower_case` to False. We are setting `do_lower_case=False` for you but you may want to check this behavior.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhrPkf0zd5va",
        "colab_type": "code",
        "outputId": "6426936b-2f7e-4eb4-9cf6-3c64b9f59d32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "## Bert Transformer 1: Text1 Delim Text2\n",
        "tokens_train_1, seg_ids_train_1 = tokenization(enzh_train_src,enzh_train_mt,tokenizer)\n",
        "tokens_val_1, seg_ids_val_1 = tokenization(enzh_dev_src,enzh_dev_mt,tokenizer)\n",
        "\n",
        "model_1 = model.to(device)\n",
        "model_1.eval()\n",
        "\n",
        "sentences_embedding_train_1 = bertProcessing(tokens_train_1,seg_ids_train_1,model_1)\n",
        "sentences_embedding_val_1 = bertProcessing(tokens_val_1,seg_ids_val_1,model_1)\n",
        "\n",
        "## Bert Transformer 2: Text2 Delim Text1\n",
        "tokens_train_2, seg_ids_train_2 = tokenization(enzh_train_mt,enzh_train_src,tokenizer)\n",
        "tokens_val_2, seg_ids_val_2 = tokenization(enzh_dev_mt,enzh_dev_src,tokenizer)\n",
        "\n",
        "model_2 = model.to(device)\n",
        "model_2.eval()\n",
        "\n",
        "sentences_embedding_train_2 = bertProcessing(tokens_train_2,seg_ids_train_2,model_2)\n",
        "sentences_embedding_val_2 = bertProcessing(tokens_val_2,seg_ids_val_2,model_2)\n",
        "\n",
        "\n",
        "## Concatenate\n",
        "sentences_embedding_train = []\n",
        "# for i in range(len(sentences_embedding_train_1)):\n",
        "#   sentences_embedding_train.append(np.add((sentences_embedding_train_1[i], sentences_embedding_train_2[i]),axis = 0))\n",
        "# # sentences_embedding_train= [np.array(sentences_embedding_train_1),np.array(sentences_embedding_train_2)]\n",
        "# X_train = np.array(sentences_embedding_train_1)\n",
        "X_train = np.sum([sentences_embedding_train_1,sentences_embedding_train_2],axis=0)\n",
        "\n",
        "sentences_embedding_val = []\n",
        "# for i in range(len(sentences_embedding_val_1)):\n",
        "#   sentences_embedding_val.append(np.add((sentences_embedding_val_1[i], sentences_embedding_val_2[i]),axis=0))\n",
        "# # sentences_embedding_val = [np.array(sentences_embedding_val_1),np.array(sentences_embedding_val_1)]\n",
        "# X_val = np.array(sentences_embedding_val_1)\n",
        "X_val = np.sum([sentences_embedding_val_1, sentences_embedding_val_2],axis = 0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "\n",
        "y_train = np.array(enzh_train_scores).astype(np.float32)\n",
        "#y_val = np.array(enzh_dev_scores).astype(np.float32)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(8000, 768)\n",
            "(1000, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5iUheGuibt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# RMSE\n",
        "def rmse(predictions, targets):\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRF391ncibaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# SVM\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train, y_train)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val)\n",
        "    pearson = pearsonr(y_val, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val)} Pearson {pearson[0]}')\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfMI9URevf67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bayes Regression\n",
        "reg = linear_model.BayesianRidge()\n",
        "reg.fit(X_train, y_train)\n",
        "predictions = reg.predict(X_val)\n",
        "pearson = pearsonr(y_val, predictions)\n",
        "print(f'RMSE: {rmse(predictions,y_val)} Pearson {pearson[0]}')\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swOPVB8glpqu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FFNN\n",
        "class FeedForwardClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(768,400)\n",
        "        self.fc2 = nn.Linear(400,100)\n",
        "        self.fc3 = nn.Linear(100,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.fc3(F.relu(self.fc2(F.relu(self.fc1(x)))))\n",
        "        return output\n",
        "\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,num_layers=2):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
        "        self.linear = nn.Linear(self.hidden_dim, output_dim)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
        "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Forward pass through LSTM layer\n",
        "        # shape of lstm_out: [input_size, batch_size, hidden_dim]\n",
        "        # shape of self.hidden: (a, b), where a and b both \n",
        "        # have shape (num_layers, batch_size, hidden_dim).\n",
        "        lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
        "        \n",
        "        # Only take the output from the final timetep\n",
        "        # Can pass on the entirety of lstm_out to the next layer if it is a seq2seq prediction\n",
        "        y_pred = self.linear(lstm_out[-1].view(self.batch_size, -1))\n",
        "        return y_pred.view(-1)\n",
        "\n",
        "\n",
        "# # RNN\n",
        "# class RNNClassification(nn.Module):\n",
        "#     def __init__(self, embedding, hiddenStates, target):\n",
        "#         super().__init__()\n",
        "#         self.lstm1 = nn.LSTM(embedding,hiddenStates) \n",
        "#         self.fc = nn.Linear(hiddenStates,target)\n",
        "\n",
        "#     def forward(self,embedding):\n",
        "#           # embedding shape(seq_len, batch_size, embedding_size) / (seq_len, embedding_size)\n",
        "#           x,_ = self.lstm1(embedding)\n",
        "#           # x reshape(embedding) to (seq_len, embedding_size)\n",
        "#           output = self.fc(x)\n",
        "#           return output\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rkr7w1ROqAUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training(model,train_loader, criterion, opt):\n",
        "  training_loss = 0\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx,(X_train, y_train) in enumerate(train_loader):\n",
        "    \n",
        "\n",
        "    X_train = X_train.view(-1,5,768).requires_grad_()\n",
        "\n",
        "    opt.zero_grad()\n",
        "\n",
        "    X_train = X_train.to(device)\n",
        "    y_train = y_train.to(device)\n",
        "\n",
        "    output = model(X_train)\n",
        "    \n",
        "    loss = criterion(output,y_train)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "\n",
        "    training_loss += torch.sqrt(loss).item()\n",
        "\n",
        "    if batch_idx % 200 == 199:\n",
        "      print('[batch: %d]  loss: %.3f'%(batch_idx+1, training_loss/200))\n",
        "      training_loss = 0\n",
        "\n",
        "def testing(model, test_loader, criterion):\n",
        "\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X_test, y_test in test_loader:\n",
        "\n",
        "      X_test = X_test.view(-1,5,768).requires_grad_()\n",
        "      \n",
        "      X_test = X_test.to(device)\n",
        "      \n",
        "      y_test = y_test.to(device)\n",
        "\n",
        "      output = model(X_test)\n",
        "\n",
        "      for pred in output.data.tolist():\n",
        "        predictions.append(pred)\n",
        "\n",
        "  #testing_loss = np.sqrt(((np.array(predictions) - np.array(y_val)) ** 2).mean())\n",
        "  \n",
        "  #pearson = pearsonr(y_val, predictions)\n",
        "\n",
        "  #print(f'testing_loss: {testing_loss} Pearson {pearson[0]}')\n",
        "\n",
        "  return predictions\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKquPLQiyJjN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def classification():\n",
        "\n",
        "  predictions = []\n",
        "  \n",
        "  train_dat = TensorDataset(torch.tensor(X_train),torch.tensor(y_train))\n",
        "  test_dat = TensorDataset(torch.tensor(X_val),torch.tensor(y_val))\n",
        "\n",
        "  train_loader = DataLoader(train_dat, batch_size=5, shuffle=True,num_workers=2)\n",
        "  val_loader = DataLoader(test_dat, batch_size=5, shuffle=False)\n",
        "\n",
        "  epochs = 3\n",
        "\n",
        "  #model = FeedForwardClassification().to(device)\n",
        "  #model = RNNClassification(768,400,1).to(device)\n",
        "\n",
        "  model = LSTM(768,500,5,1).to(device)\n",
        "  \n",
        "  opt = torch.optim.Adam(model.parameters(),lr = 0.0001)\n",
        "  \n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  for i in range(epochs):\n",
        "    print(\"Epoch: %d\"%(i))\n",
        "    print(\"-\"*30)\n",
        "    training(model,train_loader,criterion,opt)\n",
        "    predictions = testing(model,val_loader,criterion)\n",
        "    print(\"-\"*30)\n",
        "\n",
        "  writeToFile(predictions)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "e849d371-ad34-470b-9814-6176d866574b",
        "id": "Ml-mX7vSAfP_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "classification()"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "------------------------------\n",
            "[batch: 200]  loss: 0.857\n",
            "[batch: 400]  loss: 0.813\n",
            "[batch: 600]  loss: 0.794\n",
            "[batch: 800]  loss: 0.805\n",
            "[batch: 1000]  loss: 0.793\n",
            "[batch: 1200]  loss: 0.773\n",
            "[batch: 1400]  loss: 0.810\n",
            "[batch: 1600]  loss: 0.799\n",
            "------------------------------\n",
            "Epoch: 1\n",
            "------------------------------\n",
            "[batch: 200]  loss: 0.758\n",
            "[batch: 400]  loss: 0.774\n",
            "[batch: 600]  loss: 0.754\n",
            "[batch: 800]  loss: 0.772\n",
            "[batch: 1000]  loss: 0.765\n",
            "[batch: 1200]  loss: 0.753\n",
            "[batch: 1400]  loss: 0.759\n",
            "[batch: 1600]  loss: 0.725\n",
            "------------------------------\n",
            "Epoch: 2\n",
            "------------------------------\n",
            "[batch: 200]  loss: 0.738\n",
            "[batch: 400]  loss: 0.725\n",
            "[batch: 600]  loss: 0.720\n",
            "[batch: 800]  loss: 0.734\n",
            "[batch: 1000]  loss: 0.747\n",
            "[batch: 1200]  loss: 0.718\n",
            "[batch: 1400]  loss: 0.716\n",
            "[batch: 1600]  loss: 0.722\n",
            "------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdxgT-wo2jDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}