{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWxmXJ34zTfH",
        "colab_type": "text"
      },
      "source": [
        "# English to Chinese "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oGjdfOqXU3jl",
        "colab_type": "code",
        "outputId": "3d6f98b5-bf59-4002-c317-2b3de2e4e519",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "from os.path import exists\n",
        "\n",
        "if not exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-27 22:12:31--  https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
            "Resolving competitions.codalab.org (competitions.codalab.org)... 129.175.22.230\n",
            "Connecting to competitions.codalab.org (competitions.codalab.org)|129.175.22.230|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=721c29423b898e1663178bf5c911b96c7ce009321b89c78325eaecc9cec65c01&X-Amz-Date=20200227T221231Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200227%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
            "--2020-02-27 22:12:31--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=721c29423b898e1663178bf5c911b96c7ce009321b89c78325eaecc9cec65c01&X-Amz-Date=20200227T221231Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200227%2Fnewcodalab%2Fs3%2Faws4_request\n",
            "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
            "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 870893 (850K) [application/zip]\n",
            "Saving to: ‘enzh_data.zip’\n",
            "\n",
            "enzh_data.zip       100%[===================>] 850.48K  1.49MB/s    in 0.6s    \n",
            "\n",
            "2020-02-27 22:12:32 (1.49 MB/s) - ‘enzh_data.zip’ saved [870893/870893]\n",
            "\n",
            "Archive:  enzh_data.zip\n",
            "  inflating: dev.enzh.mt             \n",
            "  inflating: dev.enzh.scores         \n",
            "  inflating: dev.enzh.src            \n",
            "  inflating: test.enzh.mt            \n",
            "  inflating: test.enzh.src           \n",
            "  inflating: train.enzh.mt           \n",
            "  inflating: train.enzh.src          \n",
            "  inflating: train.enzh.scores       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D77IiOZcVPLq",
        "colab_type": "code",
        "outputId": "d0086ed5-efc6-45f3-b35d-3fb739a819f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#English-Chinese\n",
        "#Checking Data\n",
        "print(\"---EN-ZH---\")\n",
        "print()\n",
        "\n",
        "with open(\"./train.enzh.src\", \"r\") as enzh_src:\n",
        "  print(\"Source: \",enzh_src.readline())\n",
        "with open(\"./train.enzh.mt\", \"r\") as enzh_mt:\n",
        "  print(\"Translation: \",enzh_mt.readline())\n",
        "with open(\"./train.enzh.scores\", \"r\") as enzh_scores:\n",
        "  print(\"Score: \",enzh_scores.readline())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---EN-ZH---\n",
            "\n",
            "Source:  The last conquistador then rides on with his sword drawn.\n",
            "\n",
            "Translation:  最后的征服者骑着他的剑继续前进.\n",
            "\n",
            "Score:  -1.5284005772625449\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECtNpZohq8FS",
        "colab_type": "text"
      },
      "source": [
        "## English pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiDHWaJAVPsB",
        "colab_type": "code",
        "outputId": "8b87422d-ada4-4b51-ba8c-b04e5ca48156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# DON'T RUN IF YOU ALREADY RAN IT IN THE ENGLISH-GERMAN SECTION\n",
        "# Downloading spacy models for english\n",
        "\n",
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz (95.4MB)\n",
            "\u001b[K     |████████████████████████████████| 95.4MB 59.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.1.0-cp36-none-any.whl size=97126236 sha256=4556ec60ff2835475aa3d29dbd34b6634fda45d167ba66131432b3b6d9d5324d\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-c2mlqu6x/wheels/c1/2c/5f/fd7f3ec336bf97b0809c86264d2831c5dfb00fc2e239d1bb01\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_md -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en300\n",
            "You can now load the model via spacy.load('en300')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odOWt5kyVZc7",
        "colab_type": "code",
        "outputId": "b75def8f-0bb6-4b86-8e75-cbdf8914de34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import torchtext\n",
        "import spacy\n",
        "\n",
        "#Embeddings\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=100)\n",
        "\n",
        "#tokenizer model\n",
        "nlp_en =spacy.load('en300')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:29, 2.22MB/s]                           \n",
            "100%|█████████▉| 398661/400000 [00:40<00:00, 18900.48it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxs9zdVHVclc",
        "colab_type": "code",
        "outputId": "37e7a722-d780-4704-932a-58148811cdf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#ENGLISH EMBEDDINGS methods from the section GERMAN-ENGLISH\n",
        "# The difference from previous section is that we will use Glove embeddings directly because we are using a smaller model that spacy doesn't have\n",
        "# We add a method to compute the word embedding and a method to compute the sentence embedding by averaging the word vectors\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import nltk\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "\n",
        "#downloading stopwords from the nltk package\n",
        "download('stopwords') #stopwords dictionary, run once\n",
        "\n",
        "stop_words_en = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(sentence,nlp):\n",
        "    text = sentence.lower()\n",
        "    doc = [token.lemma_ for token in  nlp.tokenizer(text)]\n",
        "    doc = [word for word in doc if word not in stop_words_en]\n",
        "    doc = [word for word in doc if word.isalpha()] #restricts string to alphabetic characters only\n",
        "    return doc\n",
        "\n",
        "\n",
        "def get_word_vector(embeddings, word):\n",
        "    try:\n",
        "      vec = embeddings.vectors[embeddings.stoi[word]]\n",
        "      return vec\n",
        "    except KeyError:\n",
        "      #print(f\"Word {word} does not exist\")\n",
        "      pass\n",
        "\n",
        "def get_sentence_vector(embeddings,line):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    emb = get_word_vector(embeddings,w)\n",
        "    #do not add if the word is out of vocabulary\n",
        "    if emb is not None:\n",
        "      vectors.append(emb)\n",
        "  return torch.mean(torch.stack(vectors), axis = 0) # Mean of each word token\n",
        "\n",
        "\n",
        "def get_embeddings(f,embeddings,lang):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "\n",
        "  for l in lines:\n",
        "    sentence= preprocess(l,lang)\n",
        "    try:\n",
        "      vec = get_sentence_vector(embeddings,sentence)\n",
        "      sentences_vectors.append(vec)\n",
        "    except:\n",
        "      sentences_vectors.append(0)\n",
        "\n",
        "  return torch.stack(sentences_vectors)  ## Torch tensor\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7Z2LM47rTuY",
        "colab_type": "text"
      },
      "source": [
        "## Chinese Pre-Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jA2URyRzajGC",
        "colab_type": "code",
        "outputId": "1cc73225-9901-457c-8bbe-f30d6ec0d99a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "!wget -c https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
        "\n",
        "!wget -O zh.zip http://vectors.nlpl.eu/repository/20/35.zip\n",
        "\n",
        "!unzip zh.zip "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-27 22:27:10--  https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘chinese_stop_words.txt’\n",
            "\n",
            "\rchinese_stop_words.     [<=>                 ]       0  --.-KB/s               \rchinese_stop_words.     [ <=>                ] 419.57K  --.-KB/s    in 0.05s   \n",
            "\n",
            "2020-02-27 22:27:10 (7.85 MB/s) - ‘chinese_stop_words.txt’ saved [429642]\n",
            "\n",
            "--2020-02-27 22:27:11--  http://vectors.nlpl.eu/repository/20/35.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1458485917 (1.4G) [application/zip]\n",
            "Saving to: ‘zh.zip’\n",
            "\n",
            "zh.zip              100%[===================>]   1.36G  22.9MB/s    in 64s     \n",
            "\n",
            "2020-02-27 22:28:16 (21.9 MB/s) - ‘zh.zip’ saved [1458485917/1458485917]\n",
            "\n",
            "Archive:  zh.zip\n",
            "  inflating: LIST                    \n",
            "  inflating: meta.json               \n",
            "  inflating: model.bin               \n",
            "  inflating: model.txt               \n",
            "  inflating: README                  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8JREt60ajvj",
        "colab_type": "code",
        "outputId": "43a747c4-e233-4e51-997d-ba43c3225a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "# from gensim.test.utils import datapath\n",
        "\n",
        "\n",
        "wv_from_bin = KeyedVectors.load_word2vec_format(\"model.bin\", binary=True) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qD2OPE-iZ8b",
        "colab_type": "code",
        "outputId": "7ffc9bc6-c10e-49fd-a7e3-0753ea5f0a68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import string\n",
        "import jieba\n",
        "import gensim \n",
        "import spacy\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "\n",
        "## Create a new stopwords file !!\n",
        "stop_words = [line.rstrip() for line in open('./stopwords_ch.txt',\"r\", encoding=\"utf-8\") ]\n",
        "\n",
        "\n",
        "def get_sentence_vector_zh(line):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    try:\n",
        "      emb = wv_from_bin[w]\n",
        "      vectors.append(emb)\n",
        "    except:\n",
        "      pass #Do not add if the word is out of vocabulary\n",
        "  if vectors:\n",
        "    vectors = torch.tensor(np.array(vectors))\n",
        "    return torch.mean(vectors,axis=0)  \n",
        "  else:\n",
        "    return None\n",
        "\n",
        "\n",
        "def processing_zh(sentence):\n",
        "  wordnet_lem = WordNetLemmatizer()\n",
        "  docs = []\n",
        "  seg_list = jieba.cut(sentence)                 ## Jieba Normal model\n",
        "  doc = [word for word in seg_list if word not in stop_words]\n",
        "  for token in doc:\n",
        "    if token.isalnum() and not token.isdigit():  ## remove digits\n",
        "      if token.isalpha():                        ## Processing for english in chinese\n",
        "        token=token.lower()\n",
        "        token = wordnet_lem.lemmatize(token, pos=\"v\")\n",
        "      docs.append(token)\n",
        "  return docs\n",
        "\n",
        "\n",
        "def get_sentence_embeddings_zh(f):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "  for l in lines:\n",
        "    sent  = processing_zh(l)\n",
        "    vec = get_sentence_vector_zh(sent)\n",
        "    if vec is not None:\n",
        "      sentences_vectors.append(vec)\n",
        "    else:\n",
        "      sentences_vectors.append(torch.zeros(100))  \n",
        "  return torch.stack(sentences_vectors)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96E_zBsnsFXB",
        "colab_type": "text"
      },
      "source": [
        "## Create training and validation data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KigM_lKLiqFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "13aaa16a-6d18-4727-b727-f852e832d8c0"
      },
      "source": [
        "import spacy\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "\n",
        "\n",
        "zh_train_mt = get_sentence_embeddings_zh(\"./train.enzh.mt\")\n",
        "zh_train_src = get_embeddings(\"./train.enzh.src\",glove,nlp_en)\n",
        "f_train_scores = open(\"./train.enzh.scores\",'r')\n",
        "zh_train_scores = f_train_scores.readlines()\n",
        "\n",
        "\n",
        "zh_val_src = get_embeddings(\"./dev.enzh.src\",glove,nlp_en)\n",
        "zh_val_mt = get_sentence_embeddings_zh(\"./dev.enzh.mt\")\n",
        "f_val_scores = open(\"./dev.enzh.scores\",'r')\n",
        "zh_val_scores = f_val_scores.readlines()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.871 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nhgqtsMnBq_",
        "colab_type": "code",
        "outputId": "345e7029-cb98-45a2-d132-df1f1c8f407e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(f\"Training mt: {zh_train_mt.size()} Training src: {zh_train_src.size()}\")\n",
        "print()\n",
        "print(f\"Validation mt: {zh_val_mt.size()} Validation src: {zh_val_src.size()}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training mt: torch.Size([7000, 100]) Training src: torch.Size([7000, 100])\n",
            "\n",
            "Validation mt: torch.Size([1000, 100]) Validation src: torch.Size([1000, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUtHdWTlnIJt",
        "colab_type": "code",
        "outputId": "079d4beb-4743-450b-b92d-c16bc9141ab2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "x_train = torch.cat((zh_train_src,zh_train_mt),1)  ## Concatenate two language together\n",
        "x_val = torch.cat((zh_val_src,zh_val_mt),1)\n",
        "\n",
        "X_train_zh = np.array(x_train)\n",
        "X_val_zh = np.array(x_val)\n",
        "\n",
        "print(X_train_zh.shape)\n",
        "print(X_val_zh.shape)\n",
        "\n",
        "#Scores\n",
        "train_scores = np.array(zh_train_scores).astype(float)\n",
        "y_train_zh =train_scores\n",
        "\n",
        "val_scores = np.array(zh_val_scores).astype(float)\n",
        "y_val_zh =val_scores"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7000, 200)\n",
            "(1000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTOOadHUsVVf",
        "colab_type": "text"
      },
      "source": [
        "## Regression Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCQWDiA0nIfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from scipy.stats.stats import pearsonr\n",
        "def rmse(predictions, targets):\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thtZFy7KUQZn",
        "colab_type": "code",
        "outputId": "60d1fa3d-7135-49d4-87ca-b267b498dcfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# SVR\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_zh, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear\n",
            "RMSE: 0.9169253579770051 Pearson 0.2634595391428125\n",
            "\n",
            "poly\n",
            "RMSE: 0.9075232411468231 Pearson 0.2782473419325568\n",
            "\n",
            "rbf\n",
            "RMSE: 0.9041666243501958 Pearson 0.29848876852419753\n",
            "\n",
            "sigmoid\n",
            "RMSE: 5.667260753284455 Pearson -0.052260479449302864\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CoxNBs50UQ3t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "267bc095-9b66-450f-9292-73c35a4d5170"
      },
      "source": [
        "# Random forest\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 666)\n",
        "rf.fit(X_train_zh, y_train_zh);\n",
        "predictions = rf.predict(X_val_zh)\n",
        "\n",
        "pearson = pearsonr(y_val_zh, predictions)\n",
        "print('RMSE:', rmse(predictions,y_val_zh))\n",
        "print(f\"Pearson {pearson[0]}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.8771882560279675\n",
            "Pearson 0.2655425915807332\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwv9t5Xgsg61",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "192172b3-f5f9-48cf-cb13-7e7946abdebe"
      },
      "source": [
        "# Bayes Regression\n",
        "from sklearn.linear_model import BayesianRidge\n",
        "reg = BayesianRidge()\n",
        "reg.fit(X_train_zh, y_train_zh)\n",
        "predictions = reg.predict(X_val_zh)\n",
        "pearson = pearsonr(y_val_zh, predictions)\n",
        "print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "print()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.869678115457162 Pearson 0.293878069203704\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqfFtVQSsa2d",
        "colab_type": "text"
      },
      "source": [
        "## Neural Network regression models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM1RIYTLOgmK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os.path import exists\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim.adam\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUW_rgO7OyHj",
        "colab_type": "code",
        "outputId": "7fb7d655-ffb1-4640-96b6-1127c0838a52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "import torch\n",
        "use_GPU = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_GPU else \"cpu\")\n",
        "print('Device: ' + str(device))\n",
        "if use_GPU:\n",
        "    torch.cuda.manual_seed(0)\n",
        "    print('GPU: ' + str(torch.cuda.get_device_name(int(\"0\")))) \n",
        "print(\"Using GPU: {}\".format(use_GPU))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n",
            "GPU: Tesla P100-PCIE-16GB\n",
            "Using GPU: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jePBgALHNR8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# FFNN\n",
        "class FeedForwardClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(768,400)\n",
        "        self.fc2 = nn.Linear(400,100)\n",
        "        self.fc3 = nn.Linear(100,1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.fc3(F.relu(self.fc2(F.relu(self.fc1(x)))))\n",
        "        return output\n",
        "\n",
        "## LSTM\n",
        "class LSTM(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, batch_size, output_dim=1,num_layers=2):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(self.input_dim, self.hidden_dim, self.num_layers)\n",
        "        self.fc1 = nn.Linear(self.hidden_dim, 1)\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.zeros(self.num_layers, self.batch_size, self.hidden_dim),\n",
        "                torch.zeros(self.num_layers, self.batch_size, self.hidden_dim))\n",
        "\n",
        "    def forward(self, input):\n",
        "        lstm_out, self.hidden = self.lstm(input.view(len(input), self.batch_size, -1))\n",
        "\n",
        "        y_pred = self.fc1(lstm_out[-1].view(self.batch_size, -1))\n",
        "\n",
        "        return y_pred.view(-1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExSh0Oqls5It",
        "colab_type": "text"
      },
      "source": [
        "## Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve00D-JLNcRc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def training(model,train_loader, criterion, opt):\n",
        "  training_loss = 0\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx,(X_train, y_train) in enumerate(train_loader):\n",
        "    \n",
        "\n",
        "    X_train = X_train.view(-1,len(X_train),len(X_train[0]))\n",
        "\n",
        "    opt.zero_grad()\n",
        "\n",
        "    X_train = X_train.to(device)\n",
        "    y_train = y_train.to(device)\n",
        "\n",
        "    output = model(X_train)\n",
        "    \n",
        "    loss = criterion(output,y_train)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    opt.step()\n",
        "\n",
        "    training_loss += torch.sqrt(loss).item()\n",
        "\n",
        "    if batch_idx % 200 == 199:\n",
        "      print('[batch: %d]  loss: %.3f'%(batch_idx+1, training_loss/200))\n",
        "      training_loss = 0\n",
        "\n",
        "def testing(model, test_loader, criterion):\n",
        "\n",
        "  model.eval()\n",
        "  predictions = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for X_test, y_test in test_loader:\n",
        "\n",
        "      X_test = X_test.view(-1,len(X_test),len(X_test[0]))\n",
        "      \n",
        "      X_test = X_test.to(device)\n",
        "      \n",
        "      y_test = y_test.to(device)\n",
        "\n",
        "      output = model(X_test)\n",
        "\n",
        "      for pred in output.data.tolist():\n",
        "        predictions.append(pred)\n",
        "\n",
        "  testing_loss = np.sqrt(((np.array(predictions) - np.array(y_val_zh)) ** 2).mean())\n",
        "  \n",
        "  pearson = pearsonr(y_val_zh, predictions)\n",
        "\n",
        "  print(f'testing_loss: {testing_loss} Pearson {pearson[0]}')\n",
        "\n",
        "  return predictions, testing_loss, pearson[0]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QM-OaU_NesX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def regression():\n",
        "  bs = 4\n",
        "  epochs = 10\n",
        "  iput_dim = 200\n",
        "  hidden_dim = 750\n",
        "\n",
        "  predictions = []\n",
        "  testing_loss = []\n",
        "  pearsons = []\n",
        "  \n",
        "  train_dat = TensorDataset(torch.FloatTensor(x_train),torch.FloatTensor(y_train_zh))\n",
        "  test_dat = TensorDataset(torch.FloatTensor(x_val),torch.FloatTensor(y_val_zh))\n",
        "\n",
        "  train_loader = DataLoader(train_dat, batch_size=bs, shuffle=True,num_workers=2)\n",
        "  val_loader = DataLoader(test_dat, batch_size=bs, shuffle=False)\n",
        "\n",
        "  #model = FeedForwardClassification().to(device)\n",
        "\n",
        "  model = LSTM(iput_dim,hidden_dim,bs).to(device)\n",
        "  \n",
        "  opt = torch.optim.Adam(model.parameters(),lr = 0.0001,weight_decay=1e-6)\n",
        "  \n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  for i in range(epochs):\n",
        "    print(\"Epoch: %d\"%(i+1))\n",
        "    print(\"-\"*30)\n",
        "    training(model,train_loader,criterion,opt)\n",
        "    predictions, loss, pearson = testing(model,val_loader,criterion)\n",
        "\n",
        "    testing_loss.append(loss)\n",
        "    pearsons.append(pearson)\n",
        "\n",
        "    print(\"-\"*30)\n",
        "\n",
        "  x_epochs = list(range(1,epochs+1))\n",
        "  fig, (ax1,ax2) = plt.subplots(1,2)\n",
        "  ax1.plot(x_epochs, testing_loss)\n",
        "  ax1.set(xlabel='epochs', ylabel='test loss')\n",
        "  ax2.plot(x_epochs, pearsons)\n",
        "  ax2.set(xlabel='epochs', ylabel='test pearsons')\n",
        "  ax1.set_xticks(x_epochs) \n",
        "  ax2.set_xticks(x_epochs) \n",
        "  fig.tight_layout(pad=4.0)\n",
        "  plt.show()\n",
        "  \n",
        "  # return testing_loss, pearsons\n",
        "  # writeToFile(predictions)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "087DdPK5Nf5G",
        "colab_type": "code",
        "outputId": "692c578d-2199-47f5-a52a-b4c0d51be653",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "regression()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\n",
            "------------------------------\n",
            "[batch: 200]  loss: 0.840\n",
            "[batch: 400]  loss: 0.840\n",
            "[batch: 600]  loss: 0.848\n",
            "[batch: 800]  loss: 0.832\n",
            "[batch: 1000]  loss: 0.866\n",
            "[batch: 1200]  loss: 0.792\n",
            "[batch: 1400]  loss: 0.833\n",
            "[batch: 1600]  loss: 0.816\n",
            "testing_loss: 0.8719882906450868 Pearson 0.28771203728692263\n",
            "------------------------------\n",
            "Epoch: 2\n",
            "------------------------------\n",
            "[batch: 200]  loss: 0.804\n",
            "[batch: 400]  loss: 0.765\n",
            "[batch: 600]  loss: 0.829\n",
            "[batch: 800]  loss: 0.823\n",
            "[batch: 1000]  loss: 0.862\n",
            "[batch: 1200]  loss: 0.839\n",
            "[batch: 1400]  loss: 0.801\n",
            "[batch: 1600]  loss: 0.834\n",
            "testing_loss: 0.8688788592124971 Pearson 0.30077016163642745\n",
            "------------------------------\n",
            "Epoch: 3\n",
            "------------------------------\n",
            "[batch: 200]  loss: 0.796\n",
            "[batch: 400]  loss: 0.799\n",
            "[batch: 600]  loss: 0.830\n",
            "[batch: 800]  loss: 0.848\n",
            "[batch: 1000]  loss: 0.814\n",
            "[batch: 1200]  loss: 0.824\n",
            "[batch: 1400]  loss: 0.789\n",
            "[batch: 1600]  loss: 0.813\n",
            "testing_loss: 0.86704201451804 Pearson 0.3024435758094574\n",
            "------------------------------\n",
            "Epoch: 4\n",
            "------------------------------\n",
            "[batch: 200]  loss: 0.791\n",
            "[batch: 400]  loss: 0.816\n",
            "[batch: 600]  loss: 0.802\n",
            "[batch: 800]  loss: 0.832\n",
            "[batch: 1000]  loss: 0.812\n",
            "[batch: 1200]  loss: 0.825\n",
            "[batch: 1400]  loss: 0.838\n",
            "[batch: 1600]  loss: 0.790\n",
            "testing_loss: 0.869843900130113 Pearson 0.3051928651344593\n",
            "------------------------------\n",
            "Epoch: 5\n",
            "------------------------------\n",
            "[batch: 200]  loss: 0.833\n",
            "[batch: 400]  loss: 0.805\n",
            "[batch: 600]  loss: 0.802\n",
            "[batch: 800]  loss: 0.781\n",
            "[batch: 1000]  loss: 0.820\n",
            "[batch: 1200]  loss: 0.810\n",
            "[batch: 1400]  loss: 0.790\n",
            "[batch: 1600]  loss: 0.801\n",
            "testing_loss: 0.868306514285325 Pearson 0.3030578932650349\n",
            "------------------------------\n",
            "Epoch: 6\n",
            "------------------------------\n",
            "[batch: 200]  loss: 0.790\n",
            "[batch: 400]  loss: 0.821\n",
            "[batch: 600]  loss: 0.759\n",
            "[batch: 800]  loss: 0.767\n",
            "[batch: 1000]  loss: 0.806\n",
            "[batch: 1200]  loss: 0.817\n",
            "[batch: 1400]  loss: 0.801\n",
            "[batch: 1600]  loss: 0.808\n",
            "testing_loss: 0.8637986649466077 Pearson 0.3149728282992358\n",
            "------------------------------\n",
            "Epoch: 7\n",
            "------------------------------\n",
            "[batch: 200]  loss: 0.803\n",
            "[batch: 400]  loss: 0.784\n",
            "[batch: 600]  loss: 0.786\n",
            "[batch: 800]  loss: 0.820\n",
            "[batch: 1000]  loss: 0.784\n",
            "[batch: 1200]  loss: 0.829\n",
            "[batch: 1400]  loss: 0.777\n",
            "[batch: 1600]  loss: 0.810\n",
            "testing_loss: 0.8654969498174283 Pearson 0.31356628541170456\n",
            "------------------------------\n",
            "Epoch: 8\n",
            "------------------------------\n",
            "[batch: 200]  loss: 0.807\n",
            "[batch: 400]  loss: 0.805\n",
            "[batch: 600]  loss: 0.796\n",
            "[batch: 800]  loss: 0.788\n",
            "[batch: 1000]  loss: 0.796\n",
            "[batch: 1200]  loss: 0.805\n",
            "[batch: 1400]  loss: 0.752\n",
            "[batch: 1600]  loss: 0.797\n",
            "testing_loss: 0.8695070542187437 Pearson 0.313218315732358\n",
            "------------------------------\n",
            "Epoch: 9\n",
            "------------------------------\n",
            "[batch: 200]  loss: 0.768\n",
            "[batch: 400]  loss: 0.786\n",
            "[batch: 600]  loss: 0.825\n",
            "[batch: 800]  loss: 0.773\n",
            "[batch: 1000]  loss: 0.799\n",
            "[batch: 1200]  loss: 0.793\n",
            "[batch: 1400]  loss: 0.742\n",
            "[batch: 1600]  loss: 0.808\n",
            "testing_loss: 0.8674650668469412 Pearson 0.3066310243982183\n",
            "------------------------------\n",
            "Epoch: 10\n",
            "------------------------------\n",
            "[batch: 200]  loss: 0.748\n",
            "[batch: 400]  loss: 0.765\n",
            "[batch: 600]  loss: 0.796\n",
            "[batch: 800]  loss: 0.823\n",
            "[batch: 1000]  loss: 0.807\n",
            "[batch: 1200]  loss: 0.793\n",
            "[batch: 1400]  loss: 0.736\n",
            "[batch: 1600]  loss: 0.799\n",
            "testing_loss: 0.8724442301894313 Pearson 0.30929085090656894\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAADeCAYAAADy3YFwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6ka7J_ptBUj",
        "colab_type": "text"
      },
      "source": [
        "## Write Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHsqrgAXUS1X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def writeScores(method_name,scores):\n",
        "    fn = \"predictions.txt\"\n",
        "    print(\"\")\n",
        "    with open(fn, 'w') as output_file:\n",
        "        for idx,x in enumerate(scores):\n",
        "            #out =  metrics[idx]+\":\"+str(\"{0:.2f}\".format(x))+\"\\n\"\n",
        "            #print(out)\n",
        "            output_file.write(f\"{x}\\n\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}